{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2+9LDLcv8lz4aayLisjsS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prof-Luis1986/2A_practica01/blob/main/Tutorial_Ollama_Chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üß™ Pr√°ctica guiada: Chat con Flet + Ollama (local)**"
      ],
      "metadata": {
        "id": "s5nhdLI3_lpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objetivo\n",
        "\n",
        "Que el alumnado:\n",
        "\n",
        "Instale y pruebe Ollama y un modelo local.\n",
        "\n",
        "Cree un proyecto Flet con flet create.\n",
        "\n",
        "Arme la UI b√°sica, conecte con Ollama y muestre la respuesta en vivo (streaming).\n",
        "\n",
        "A√±ada TTS al final de cada respuesta.\n",
        "\n",
        "Ajuste tokens para rendimiento."
      ],
      "metadata": {
        "id": "a2wtaW_J_09b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0) Requisitos\n",
        "\n",
        "Python 3.10+\n",
        "\n",
        "Internet (solo para descargar Ollama y el modelo la primera vez)"
      ],
      "metadata": {
        "id": "F8P748qm_5O1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Instalar Ollama\n",
        "Windows\n",
        "\n",
        "Descargar e instalar Ollama desde su web (instalador .exe).\n",
        "\n",
        "Abrir PowerShell y comprobar:"
      ],
      "metadata": {
        "id": "AGI9tjo0_6Rx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HNWEKVZ_eUJ"
      },
      "outputs": [],
      "source": [
        "ollama --version\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si no arranca solo, ejecuta:"
      ],
      "metadata": {
        "id": "5sYRBTIjAC79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ollama serve\n"
      ],
      "metadata": {
        "id": "7lxRVEdiAMMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "macOS\n",
        "\n",
        "Instalar con el .pkg (o v√≠a Homebrew: brew install ollama).\n",
        "\n",
        "Verificar en Terminal:"
      ],
      "metadata": {
        "id": "iMxVsHCLAZVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ollama --version\n"
      ],
      "metadata": {
        "id": "VAenxiIKAdx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Descargar el modelo (ligero y r√°pido)\n",
        "\n",
        "Usaremos Qwen 2.5 (3B) para baja latencia."
      ],
      "metadata": {
        "id": "oACzuAdOAfYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ollama pull qwen2.5:3b\n"
      ],
      "metadata": {
        "id": "W2QrDEEhAjDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprueba lo instalado:"
      ],
      "metadata": {
        "id": "kWYOItzCAoky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ollama list\n"
      ],
      "metadata": {
        "id": "6XEXolI6ApjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Crear el proyecto con Flet\n",
        "\n",
        "Instalar Flet (si hace falta):"
      ],
      "metadata": {
        "id": "ptQXLvAgA7pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flet\n"
      ],
      "metadata": {
        "id": "ZsDgOjsmA8yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear la proyecto:"
      ],
      "metadata": {
        "id": "iv1rJsYCA_aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flet create Appollama_voz\n",
        "cd Appollama_voz\n"
      ],
      "metadata": {
        "id": "_9b-yFpSBDS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Recomendado) Entorno virtual:\n",
        "Windows (PowerShell):"
      ],
      "metadata": {
        "id": "6F2JY0p2BNvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python -m venv .venv\n",
        ".\\.venv\\Scripts\\activate\n"
      ],
      "metadata": {
        "id": "F_Wzju5iBYft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "macOS:"
      ],
      "metadata": {
        "id": "_fwGvAv9Bfrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python -m venv .venv\n",
        "source .venv/bin/activate\n"
      ],
      "metadata": {
        "id": "PESelN4jBh7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependencias extra:"
      ],
      "metadata": {
        "id": "gFnPGlIaBk38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests pyttsx3\n"
      ],
      "metadata": {
        "id": "DwWgqG0aBnsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0jn7hv9fBt3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Probar Flet ‚ÄúHola mundo‚Äù\n",
        "\n",
        "Abre main.py y deja este m√≠nimo:"
      ],
      "metadata": {
        "id": "lYb-4WeyBtIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flet as ft\n",
        "\n",
        "def main(page: ft.Page):\n",
        "    page.title = \"Hola Flet\"\n",
        "    page.add(ft.Text(\"¬°Hola, Flet!\"))\n",
        "\n",
        "ft.app(target=main)\n"
      ],
      "metadata": {
        "id": "lxYiNyyWBv6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecuta."
      ],
      "metadata": {
        "id": "AtS_7XeZBy9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Estructuremos el  chat con ollama.***"
      ],
      "metadata": {
        "id": "YKHZyu3mmySx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 1 ‚Äî Imports"
      ],
      "metadata": {
        "id": "0gLiTazom_rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flet as ft\n",
        "import requests\n",
        "import json\n",
        "import pyttsx3\n",
        "import platform\n",
        "import os"
      ],
      "metadata": {
        "id": "d5S6vV6lm_Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este bloque?\n",
        "\n",
        "* Carga las librer√≠as que la app necesita:\n",
        "\n",
        "* flet: para construir la interfaz gr√°fica.\n",
        "\n",
        "* requests: para conectarnos con el modelo Ollama v√≠a HTTP.\n",
        "\n",
        "* json: para leer e interpretar las respuestas del modelo.\n",
        "\n",
        "* pyttsx3: para convertir texto a voz (TTS).\n",
        "\n",
        "* platform y os: para detectar el sistema operativo y ejecutar comandos en el sistema.\n",
        "\n",
        "Errores t√≠picos:\n",
        "\n",
        "* ModuleNotFoundError: falta instalar las librer√≠as con pip.\n",
        "\n",
        "Buenas pr√°cticas:\n",
        "\n",
        "* Mantener todos los imports organizados al inicio del archivo."
      ],
      "metadata": {
        "id": "hrDUWw4onG9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 2 ‚Äî Detecci√≥n de sistema y selecci√≥n de personaje/voz"
      ],
      "metadata": {
        "id": "eLqzTaUXogOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== CONFIG ========\n",
        "SO = platform.system()\n",
        "\n",
        "if SO == \"Darwin\":  # Mac\n",
        "    PERSONAJE = \"Albert Einstein\"\n",
        "    EMOJI_PERSONAJE = \"üßë‚Äçüî¨\"\n",
        "    VOZ = \"Juan\"\n",
        "elif SO == \"Windows\":\n",
        "    PERSONAJE = \"Marie Curie\"\n",
        "    EMOJI_PERSONAJE = \"üë©‚Äçüî¨\"\n",
        "    VOZ = \"Sabina\"  # o \"Zira\"\n",
        "else:\n",
        "    PERSONAJE = \"Personaje\"\n",
        "    EMOJI_PERSONAJE = \"üßë‚Äçüî¨\"\n",
        "    VOZ = None"
      ],
      "metadata": {
        "id": "703QQ-Msog6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este bloque?\n",
        "\n",
        "* Detecta el sistema operativo en el que corre la app.\n",
        "\n",
        "* Seg√∫n el sistema, define qu√© personaje hist√≥rico aparecer√°, con su emoji y voz.\n",
        "\n",
        "* En otros sistemas (Linux, etc.) desactiva la voz.\n",
        "\n",
        "Errores t√≠picos:\n",
        "\n",
        "* Que la voz seleccionada no exista en tu sistema.\n",
        "\n",
        "Buenas pr√°cticas:\n",
        "\n",
        "* Ajustar los nombres de voz seg√∫n el sistema operativo usado."
      ],
      "metadata": {
        "id": "D3WJj9reomQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 3 ‚Äî Emojis, endpoint de Ollama y modelo"
      ],
      "metadata": {
        "id": "hcnDwzhVoxNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMOJI_USUARIO = \"üßë‚Äçüíª\"\n",
        "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "\n",
        "# Modelo ligero para velocidad\n",
        "MODEL = \"qwen2.5:3b\"  # puedes probar \"gemma3:latest\" o \"mistral:7b\"\n",
        "\n",
        "# Opciones ajustadas para rapidez\n",
        "OLLAMA_OPTIONS = {\n",
        "    \"num_ctx\": 4096,\n",
        "    \"num_predict\": 512,\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_p\": 0.9,\n",
        "    \"repeat_penalty\": 1.1,\n",
        "}\n",
        "KEEP_ALIVE = \"30m\""
      ],
      "metadata": {
        "id": "DRpH79bZo0Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este bloque?\n",
        "\n",
        "* Define el emoji del usuario.\n",
        "\n",
        "* Indica la direcci√≥n del servidor local de Ollama.\n",
        "\n",
        "* Selecciona el modelo de IA a utilizar.\n",
        "\n",
        "* Configura par√°metros de la generaci√≥n de texto.\n",
        "\n",
        "* Mantiene cargado el modelo por 30 minutos aunque no se use.\n",
        "\n",
        "Errores t√≠picos:\n",
        "\n",
        "* Si el servidor Ollama no est√° corriendo, no habr√° respuesta.\n",
        "\n",
        "* Puede que falte descargar el modelo (ollama pull qwen2.5:3b)."
      ],
      "metadata": {
        "id": "7cEYBSQVo5wD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 4 ‚Äî Sesi√≥n HTTP y funci√≥n de voz hablar"
      ],
      "metadata": {
        "id": "L9bYDNJzpFT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reutiliza la conexi√≥n HTTP\n",
        "session = requests.Session()\n",
        "\n",
        "# Reutiliza motor TTS en Windows\n",
        "_tts_engine = None\n",
        "\n",
        "def hablar(texto, voz=VOZ):\n",
        "    global _tts_engine\n",
        "    texto_limpio = texto.replace(\"*\", \"\").replace(\"_\", \"\").replace(\"#\", \"\")\n",
        "    if SO == \"Darwin\":\n",
        "        os.system(f'say -v \"{voz}\" \"{texto_limpio}\"')\n",
        "    elif SO == \"Windows\":\n",
        "        try:\n",
        "            if _tts_engine is None:\n",
        "                _tts_engine = pyttsx3.init()\n",
        "                if voz:\n",
        "                    for v in _tts_engine.getProperty('voices'):\n",
        "                        if voz.lower() in v.name.lower():\n",
        "                            _tts_engine.setProperty('voice', v.id)\n",
        "                            break\n",
        "                _tts_engine.setProperty('rate', 160)\n",
        "                _tts_engine.setProperty('volume', 0.9)\n",
        "            _tts_engine.say(texto_limpio)\n",
        "            _tts_engine.runAndWait()\n",
        "        except Exception as e:\n",
        "            print(f\"Error en TTS: {e}\")"
      ],
      "metadata": {
        "id": "mjMy1pVfpIsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este bloque?\n",
        "\n",
        "* Crea una sesi√≥n HTTP para hacer peticiones al servidor de IA.\n",
        "\n",
        "* Define la funci√≥n hablar() para que el personaje pueda leer la respuesta en voz alta.\n",
        "\n",
        "* Ajusta voz, velocidad y volumen seg√∫n el sistema operativo.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ocfx9B9ApQEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 5 ‚Äî Funci√≥n main: ventana y contenedores base"
      ],
      "metadata": {
        "id": "SnzguoM9pXPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(page: ft.Page):\n",
        "    page.title = f\"Chat con {PERSONAJE}\"\n",
        "    page.bgcolor = ft.Colors.GREY_100\n",
        "\n",
        "    mensajes = ft.ListView(\n",
        "        expand=True, spacing=10, padding=20, auto_scroll=True\n",
        "    )"
      ],
      "metadata": {
        "id": "OQfB4yollDwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este bloque?\n",
        "\n",
        "* Crea la ventana principal del chat.\n",
        "\n",
        "* Muestra un √°rea donde aparecer√°n los mensajes.\n",
        "\n",
        "* auto_scroll=True hace que la vista se mueva sola hacia abajo."
      ],
      "metadata": {
        "id": "dbQUgADglINW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 6 ‚Äî Burbujas de chat (usuario vs personaje)\n",
        "\n",
        "\n",
        "Dibuja cada mensaje en una ‚Äúburbuja‚Äù con color/alineaci√≥n distintos para usuario y personaje. Se usa dentro de main()."
      ],
      "metadata": {
        "id": "cA7czwbGpg1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def burbuja(texto, es_usuario):\n",
        "    return ft.Row(\n",
        "        [\n",
        "            ft.Text(EMOJI_USUARIO if es_usuario else EMOJI_PERSONAJE, size=24),\n",
        "            ft.Container(\n",
        "                content=ft.Text(\n",
        "                    texto,\n",
        "                    color=ft.Colors.WHITE if es_usuario else ft.Colors.BLACK,\n",
        "                    size=15,\n",
        "                    selectable=True,\n",
        "                ),\n",
        "                bgcolor=ft.Colors.BLUE_400 if es_usuario else ft.Colors.GREY_300,\n",
        "                padding=12,\n",
        "                border_radius=30,\n",
        "                shadow=ft.BoxShadow(blur_radius=8, color=ft.Colors.GREY_400, offset=ft.Offset(2, 2)),\n",
        "                margin=ft.margin.only(left=10) if es_usuario else ft.margin.only(right=10),\n",
        "                alignment=ft.alignment.center_right if es_usuario else ft.alignment.center_left,\n",
        "                width=350,\n",
        "            )\n",
        "        ] if es_usuario else [\n",
        "            ft.Container(\n",
        "                content=ft.Text(\n",
        "                    texto,\n",
        "                    color=ft.Colors.BLACK,\n",
        "                    size=15,\n",
        "                    selectable=True,\n",
        "                ),\n",
        "                bgcolor=ft.Colors.GREY_300,\n",
        "                padding=12,\n",
        "                border_radius=30,\n",
        "                shadow=ft.BoxShadow(blur_radius=8, color=ft.Colors.GREY_400, offset=ft.Offset(2, 2)),\n",
        "                margin=ft.margin.only(right=10),\n",
        "                alignment=ft.alignment.center_left,\n",
        "                width=350,\n",
        "            ),\n",
        "            ft.Text(EMOJI_PERSONAJE, size=24),\n",
        "        ],\n",
        "        alignment=ft.MainAxisAlignment.END if es_usuario else ft.MainAxisAlignment.START,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "u2eOWfaApgfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este bloque?\n",
        "\n",
        "* Dibuja cada mensaje como burbuja.\n",
        "\n",
        "* Cambia color/alineaci√≥n seg√∫n si habla el usuario o el personaje.\n",
        "\n",
        "* Muestra el emoji correspondiente a cada lado."
      ],
      "metadata": {
        "id": "22eSgJwHqejd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 7 ‚Äî Entrada de texto y checkbox de voz"
      ],
      "metadata": {
        "id": "zGqau6EZqtIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ft.TextField(\n",
        "    label=\"Escribe tu mensaje...\",\n",
        "    expand=True,\n",
        "    border_radius=20,\n",
        "    filled=True,\n",
        "    bgcolor=ft.Colors.WHITE,\n",
        "    multiline=True,\n",
        "    min_lines=1,\n",
        "    max_lines=4,\n",
        ")\n",
        "\n",
        "voz_activada = ft.Checkbox(label=\"üîä Leer respuestas en voz alta\", value=True)\n"
      ],
      "metadata": {
        "id": "qGGlw1OdqwVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este bloque?\n",
        "\n",
        "* TextField para que el alumno escriba su mensaje (hasta 4 l√≠neas).\n",
        "\n",
        "* Checkbox para activar/desactivar que el personaje lea en voz alta (TTS)."
      ],
      "metadata": {
        "id": "EMOv-Kojq45b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 8 ‚Äî enviar_click: preguntar al modelo y streaming de respuesta"
      ],
      "metadata": {
        "id": "96KFmkU2q_ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enviar_click(e):\n",
        "    user_input = prompt.value.strip()\n",
        "    if not user_input:\n",
        "        return\n",
        "\n",
        "    # Muestra mensaje del usuario\n",
        "    mensajes.controls.append(burbuja(user_input, es_usuario=True))\n",
        "    page.update()\n",
        "    prompt.value = \"\"\n",
        "    page.update()\n",
        "\n",
        "    # Construir prompt\n",
        "    prompt_personaje = (\n",
        "        f\"Responde como si fueras {PERSONAJE}. \"\n",
        "        \"Habla con su estilo, conocimientos y personalidad. \"\n",
        "        \"Responde en espa√±ol de manera clara y concisa. \"\n",
        "        f\"Pregunta del usuario: {user_input}\"\n",
        "    )\n",
        "\n",
        "    # Crear contenedor vac√≠o para la respuesta\n",
        "    respuesta_live = ft.Text(\"\", color=ft.Colors.BLACK, size=15, selectable=True)\n",
        "    contenedor_bot = ft.Row([\n",
        "        ft.Container(\n",
        "            content=respuesta_live,\n",
        "            bgcolor=ft.Colors.GREY_300,\n",
        "            padding=12,\n",
        "            border_radius=30,\n",
        "            width=350,\n",
        "        ),\n",
        "        ft.Text(EMOJI_PERSONAJE, size=24),\n",
        "    ], alignment=ft.MainAxisAlignment.START)\n",
        "\n",
        "    mensajes.controls.append(contenedor_bot)\n",
        "    page.update()\n",
        "\n",
        "    try:\n",
        "        resp = session.post(\n",
        "            OLLAMA_URL,\n",
        "            json={\n",
        "                \"model\": MODEL,\n",
        "                \"prompt\": prompt_personaje,\n",
        "                \"stream\": True,\n",
        "                \"keep_alive\": KEEP_ALIVE,\n",
        "                \"options\": OLLAMA_OPTIONS\n",
        "            },\n",
        "            stream=True,\n",
        "            timeout=300,\n",
        "        )\n",
        "        resp.raise_for_status()\n",
        "\n",
        "        texto_final = \"\"\n",
        "        # üî• Streaming incremental: escribe token por token\n",
        "        for line in resp.iter_lines():\n",
        "            if not line:\n",
        "                continue\n",
        "            data = json.loads(line)\n",
        "            if \"response\" in data:\n",
        "                chunk = data[\"response\"]\n",
        "                texto_final += chunk\n",
        "                respuesta_live.value = texto_final\n",
        "                page.update()   # refresca pantalla en cada token\n",
        "            elif \"error\" in data:\n",
        "                texto_final = f\"Error de Ollama: {data['error']}\"\n",
        "                break\n",
        "\n",
        "        if not texto_final:\n",
        "            texto_final = \"No se recibi√≥ respuesta del modelo.\"\n",
        "\n",
        "        respuesta_live.value = texto_final\n",
        "        page.update()\n",
        "\n",
        "        # TTS al final (no en streaming)\n",
        "        if voz_activada.value and VOZ:\n",
        "            try:\n",
        "                hablar(texto_final, voz=VOZ)\n",
        "            except Exception as ex:\n",
        "                print(f\"Error en TTS: {ex}\")\n",
        "\n",
        "    except Exception as ex:\n",
        "        respuesta_live.value = f\"Error de conexi√≥n o inesperado: {ex}\"\n",
        "        page.update()\n"
      ],
      "metadata": {
        "id": "JLwkzfvcq_W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este bloque?\n",
        "\n",
        "* Agrega la burbuja del alumno y limpia el input.\n",
        "\n",
        "* Manda la petici√≥n a Ollama y muestra la respuesta en tiempo real.\n",
        "\n",
        "* Si la casilla est√° activa y hay voz disponible, lee en voz alta al final."
      ],
      "metadata": {
        "id": "KIOKlvAcrQgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 9 ‚Äî Eventos y utilidades (Enter, probar voz, limpiar chat)"
      ],
      "metadata": {
        "id": "3Cku7BA-rht-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.on_submit = enviar_click\n",
        "\n",
        "def probar_voz(e):\n",
        "    if VOZ:\n",
        "        hablar(f\"Hola, soy {PERSONAJE}. Esta es mi voz.\", voz=VOZ)\n",
        "\n",
        "def limpiar_chat(e):\n",
        "    mensajes.controls.clear()\n",
        "    page.update()\n"
      ],
      "metadata": {
        "id": "EtVigFDZrg_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este bloque?\n",
        "\n",
        "* Enter env√≠a el mensaje (on_submit).\n",
        "\n",
        "* Bot√≥n üé§ Probar voz para escuchar la voz configurada.\n",
        "\n",
        "* üßπ Limpiar chat borra el historial visual."
      ],
      "metadata": {
        "id": "HVvSlm0Arzuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 10 ‚Äî Header, layout final y arranque"
      ],
      "metadata": {
        "id": "WREgmZU3r8rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- dentro de main ---\n",
        "header = ft.Container(\n",
        "    content=ft.Row([\n",
        "        ft.Text(EMOJI_PERSONAJE, size=32),\n",
        "        ft.Text(PERSONAJE, size=22, weight=\"bold\", color=ft.Colors.BLUE_900),\n",
        "    ], alignment=ft.MainAxisAlignment.START, spacing=15),\n",
        "    padding=ft.padding.symmetric(vertical=16, horizontal=10),\n",
        "    bgcolor=ft.Colors.WHITE,\n",
        "    border_radius=ft.border_radius.only(top_left=20, top_right=20),\n",
        "    shadow=ft.BoxShadow(blur_radius=12, color=ft.Colors.GREY_300, offset=ft.Offset(0, 2))\n",
        ")\n",
        "\n",
        "page.add(\n",
        "    ft.Container(\n",
        "        content=ft.Column([\n",
        "            header,\n",
        "            mensajes,\n",
        "            ft.Row([\n",
        "                voz_activada,\n",
        "                ft.ElevatedButton(\"üé§ Probar voz\", on_click=probar_voz, bgcolor=ft.Colors.GREEN_400, color=ft.Colors.WHITE),\n",
        "                ft.TextButton(\"üßπ Limpiar chat\", on_click=limpiar_chat),\n",
        "            ], alignment=ft.MainAxisAlignment.START, spacing=10),\n",
        "            ft.Row([\n",
        "                prompt,\n",
        "                ft.ElevatedButton(\"Enviar\", on_click=enviar_click, bgcolor=ft.Colors.BLUE_400, color=ft.Colors.WHITE),\n",
        "            ], vertical_alignment=ft.CrossAxisAlignment.END),\n",
        "        ], expand=True, spacing=10),\n",
        "        expand=True,\n",
        "        padding=0,\n",
        "        border_radius=0,\n",
        "        bgcolor=ft.Colors.WHITE,\n",
        "    )\n",
        ")\n",
        "\n",
        "# --- fuera de main ---\n",
        "ft.app(target=main)\n"
      ],
      "metadata": {
        "id": "QBk3Q7tlr-y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este bloque?\n",
        "\n",
        "* Crea la cabecera (emoji + nombre del personaje).\n",
        "\n",
        "* Organiza la interfaz (historial, controles de voz, botones, input).\n",
        "\n",
        "* Lanza la app con ft.app(target=main)."
      ],
      "metadata": {
        "id": "vhlX8WKbr_y-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codig√≥ Completo"
      ],
      "metadata": {
        "id": "KmDhucc1tqf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flet as ft\n",
        "import requests\n",
        "import json\n",
        "import pyttsx3\n",
        "import platform\n",
        "import os\n",
        "\n",
        "# ======== CONFIG ========\n",
        "SO = platform.system()\n",
        "\n",
        "if SO == \"Darwin\":  # Mac\n",
        "    PERSONAJE = \"Albert Einstein\"\n",
        "    EMOJI_PERSONAJE = \"üßë‚Äçüî¨\"\n",
        "    VOZ = \"Juan\"\n",
        "elif SO == \"Windows\":\n",
        "    PERSONAJE = \"Marie Curie\"\n",
        "    EMOJI_PERSONAJE = \"üë©‚Äçüî¨\"\n",
        "    VOZ = \"Sabina\"  # o \"Zira\"\n",
        "else:\n",
        "    PERSONAJE = \"Personaje\"\n",
        "    EMOJI_PERSONAJE = \"üßë‚Äçüî¨\"\n",
        "    VOZ = None\n",
        "\n",
        "EMOJI_USUARIO = \"üßë‚Äçüíª\"\n",
        "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "\n",
        "# Modelo ligero para velocidad\n",
        "MODEL = \"qwen2.5:3b\"  # puedes probar \"gemma3:latest\" o \"mistral:7b\"\n",
        "\n",
        "# Opciones ajustadas para rapidez\n",
        "OLLAMA_OPTIONS = {\n",
        "    \"num_ctx\": 4096,       # tokens de contexto\n",
        "    \"num_predict\": 512,    # tokens m√°ximos de salida\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_p\": 0.9,\n",
        "    \"repeat_penalty\": 1.1,\n",
        "}\n",
        "KEEP_ALIVE = \"30m\"\n",
        "\n",
        "# Reutiliza la conexi√≥n HTTP\n",
        "session = requests.Session()\n",
        "\n",
        "# Reutiliza motor TTS en Windows\n",
        "_tts_engine = None\n",
        "def hablar(texto, voz=VOZ):\n",
        "    global _tts_engine\n",
        "    texto_limpio = texto.replace(\"*\", \"\").replace(\"_\", \"\").replace(\"#\", \"\")\n",
        "    if SO == \"Darwin\":\n",
        "        os.system(f'say -v \"{voz}\" \"{texto_limpio}\"')\n",
        "    elif SO == \"Windows\":\n",
        "        try:\n",
        "            if _tts_engine is None:\n",
        "                _tts_engine = pyttsx3.init()\n",
        "                if voz:\n",
        "                    for v in _tts_engine.getProperty('voices'):\n",
        "                        if voz.lower() in v.name.lower():\n",
        "                            _tts_engine.setProperty('voice', v.id)\n",
        "                            break\n",
        "                _tts_engine.setProperty('rate', 160)\n",
        "                _tts_engine.setProperty('volume', 0.9)\n",
        "            _tts_engine.say(texto_limpio)\n",
        "            _tts_engine.runAndWait()\n",
        "        except Exception as e:\n",
        "            print(f\"Error en TTS: {e}\")\n",
        "\n",
        "def main(page: ft.Page):\n",
        "    page.title = f\"Chat con {PERSONAJE}\"\n",
        "    page.bgcolor = ft.Colors.GREY_100\n",
        "\n",
        "    mensajes = ft.ListView(expand=True, spacing=10, padding=20, auto_scroll=True)\n",
        "\n",
        "    def burbuja(texto, es_usuario):\n",
        "        return ft.Row(\n",
        "            [\n",
        "                ft.Text(EMOJI_USUARIO if es_usuario else EMOJI_PERSONAJE, size=24),\n",
        "                ft.Container(\n",
        "                    content=ft.Text(\n",
        "                        texto,\n",
        "                        color=ft.Colors.WHITE if es_usuario else ft.Colors.BLACK,\n",
        "                        size=15,\n",
        "                        selectable=True,\n",
        "                    ),\n",
        "                    bgcolor=ft.Colors.BLUE_400 if es_usuario else ft.Colors.GREY_300,\n",
        "                    padding=12,\n",
        "                    border_radius=30,\n",
        "                    shadow=ft.BoxShadow(blur_radius=8, color=ft.Colors.GREY_400, offset=ft.Offset(2, 2)),\n",
        "                    margin=ft.margin.only(left=10) if es_usuario else ft.margin.only(right=10),\n",
        "                    alignment=ft.alignment.center_right if es_usuario else ft.alignment.center_left,\n",
        "                    width=350,\n",
        "                )\n",
        "            ] if es_usuario else [\n",
        "                ft.Container(\n",
        "                    content=ft.Text(\n",
        "                        texto,\n",
        "                        color=ft.Colors.BLACK,\n",
        "                        size=15,\n",
        "                        selectable=True,\n",
        "                    ),\n",
        "                    bgcolor=ft.Colors.GREY_300,\n",
        "                    padding=12,\n",
        "                    border_radius=30,\n",
        "                    shadow=ft.BoxShadow(blur_radius=8, color=ft.Colors.GREY_400, offset=ft.Offset(2, 2)),\n",
        "                    margin=ft.margin.only(right=10),\n",
        "                    alignment=ft.alignment.center_left,\n",
        "                    width=350,\n",
        "                ),\n",
        "                ft.Text(EMOJI_PERSONAJE, size=24),\n",
        "            ],\n",
        "            alignment=ft.MainAxisAlignment.END if es_usuario else ft.MainAxisAlignment.START,\n",
        "        )\n",
        "\n",
        "    prompt = ft.TextField(\n",
        "        label=\"Escribe tu mensaje...\",\n",
        "        expand=True,\n",
        "        border_radius=20,\n",
        "        filled=True,\n",
        "        bgcolor=ft.Colors.WHITE,\n",
        "        multiline=True,\n",
        "        min_lines=1,\n",
        "        max_lines=4,\n",
        "    )\n",
        "\n",
        "    voz_activada = ft.Checkbox(label=\"üîä Leer respuestas en voz alta\", value=True)\n",
        "\n",
        "    def enviar_click(e):\n",
        "        user_input = prompt.value.strip()\n",
        "        if not user_input:\n",
        "            return\n",
        "\n",
        "        # Muestra mensaje del usuario\n",
        "        mensajes.controls.append(burbuja(user_input, es_usuario=True))\n",
        "        page.update()\n",
        "        prompt.value = \"\"\n",
        "        page.update()\n",
        "\n",
        "        # Construir prompt\n",
        "        prompt_personaje = (\n",
        "            f\"Responde como si fueras {PERSONAJE}. \"\n",
        "            \"Habla con su estilo, conocimientos y personalidad. \"\n",
        "            \"Responde en espa√±ol de manera clara y concisa. \"\n",
        "            f\"Pregunta del usuario: {user_input}\"\n",
        "        )\n",
        "\n",
        "        # Crear contenedor vac√≠o para la respuesta\n",
        "        respuesta_live = ft.Text(\"\", color=ft.Colors.BLACK, size=15, selectable=True)\n",
        "        contenedor_bot = ft.Row([\n",
        "            ft.Container(\n",
        "                content=respuesta_live,\n",
        "                bgcolor=ft.Colors.GREY_300,\n",
        "                padding=12,\n",
        "                border_radius=30,\n",
        "                width=350,\n",
        "            ),\n",
        "            ft.Text(EMOJI_PERSONAJE, size=24),\n",
        "        ], alignment=ft.MainAxisAlignment.START)\n",
        "\n",
        "        mensajes.controls.append(contenedor_bot)\n",
        "        page.update()\n",
        "\n",
        "        try:\n",
        "            resp = session.post(\n",
        "                OLLAMA_URL,\n",
        "                json={\n",
        "                    \"model\": MODEL,\n",
        "                    \"prompt\": prompt_personaje,\n",
        "                    \"stream\": True,\n",
        "                    \"keep_alive\": KEEP_ALIVE,\n",
        "                    \"options\": OLLAMA_OPTIONS\n",
        "                },\n",
        "                stream=True,\n",
        "                timeout=300,\n",
        "            )\n",
        "            resp.raise_for_status()\n",
        "\n",
        "            texto_final = \"\"\n",
        "            # üî• Streaming incremental: escribe token por token\n",
        "            for line in resp.iter_lines():\n",
        "                if not line:\n",
        "                    continue\n",
        "                data = json.loads(line)\n",
        "                if \"response\" in data:\n",
        "                    chunk = data[\"response\"]\n",
        "                    texto_final += chunk\n",
        "                    respuesta_live.value = texto_final\n",
        "                    page.update()   # refresca pantalla en cada token\n",
        "                elif \"error\" in data:\n",
        "                    texto_final = f\"Error de Ollama: {data['error']}\"\n",
        "                    break\n",
        "\n",
        "            if not texto_final:\n",
        "                texto_final = \"No se recibi√≥ respuesta del modelo.\"\n",
        "\n",
        "            respuesta_live.value = texto_final\n",
        "            page.update()\n",
        "\n",
        "            # TTS al final (no en streaming)\n",
        "            if voz_activada.value and VOZ:\n",
        "                try:\n",
        "                    hablar(texto_final, voz=VOZ)\n",
        "                except Exception as ex:\n",
        "                    print(f\"Error en TTS: {ex}\")\n",
        "\n",
        "        except Exception as ex:\n",
        "            respuesta_live.value = f\"Error de conexi√≥n o inesperado: {ex}\"\n",
        "            page.update()\n",
        "\n",
        "    prompt.on_submit = enviar_click\n",
        "\n",
        "    def probar_voz(e):\n",
        "        if VOZ:\n",
        "            hablar(f\"Hola, soy {PERSONAJE}. Esta es mi voz.\", voz=VOZ)\n",
        "\n",
        "    def limpiar_chat(e):\n",
        "        mensajes.controls.clear()\n",
        "        page.update()\n",
        "\n",
        "    header = ft.Container(\n",
        "        content=ft.Row([\n",
        "            ft.Text(EMOJI_PERSONAJE, size=32),\n",
        "            ft.Text(PERSONAJE, size=22, weight=\"bold\", color=ft.Colors.BLUE_900),\n",
        "        ], alignment=ft.MainAxisAlignment.START, spacing=15),\n",
        "        padding=ft.padding.symmetric(vertical=16, horizontal=10),\n",
        "        bgcolor=ft.Colors.WHITE,\n",
        "        border_radius=ft.border_radius.only(top_left=20, top_right=20),\n",
        "        shadow=ft.BoxShadow(blur_radius=12, color=ft.Colors.GREY_300, offset=ft.Offset(0, 2))\n",
        "    )\n",
        "\n",
        "    page.add(\n",
        "        ft.Container(\n",
        "            content=ft.Column([\n",
        "                header,\n",
        "                mensajes,\n",
        "                ft.Row([\n",
        "                    voz_activada,\n",
        "                    ft.ElevatedButton(\"üé§ Probar voz\", on_click=probar_voz, bgcolor=ft.Colors.GREEN_400, color=ft.Colors.WHITE),\n",
        "                    ft.TextButton(\"üßπ Limpiar chat\", on_click=limpiar_chat),\n",
        "                ], alignment=ft.MainAxisAlignment.START, spacing=10),\n",
        "                ft.Row([\n",
        "                    prompt,\n",
        "                    ft.ElevatedButton(\"Enviar\", on_click=enviar_click, bgcolor=ft.Colors.BLUE_400, color=ft.Colors.WHITE),\n",
        "                ], vertical_alignment=ft.CrossAxisAlignment.END),\n",
        "            ], expand=True, spacing=10),\n",
        "            expand=True,\n",
        "            padding=0,\n",
        "            border_radius=0,\n",
        "            bgcolor=ft.Colors.WHITE,\n",
        "        )\n",
        "    )\n",
        "\n",
        "ft.app(target=main)\n"
      ],
      "metadata": {
        "id": "Xn38mn8vtxxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Responde estas preguntas en tu google sites.\n",
        "\n",
        "1. ¬øQu√© versiones de Python se recomiendan para este proyecto?\n",
        "\n",
        "2. ¬øPor qu√© se necesita conexi√≥n a internet al menos la primera vez?\n",
        "\n",
        "3. ¬øQu√© comando crea la carpeta base del proyecto con Flet?\n",
        "\n",
        "4. Escribe el comando para activar tu venv en tu sistema (macOS o Windows).\n",
        "\n",
        "5. ¬øDesde qu√© URL oficial se descarga Ollama?\n",
        "\n",
        "6. ¬øQu√© comando descarga el modelo qwen2.5:3b?\n",
        "\n",
        "7. ¬øQu√© modelo de IA usa el proyecto por defecto?\n",
        "\n",
        "8. ¬øPara qu√© sirve la variable KEEP_ALIVE?\n",
        "\n",
        "9. ¬øQu√© librer√≠a se usa para la interfaz gr√°fica?\n",
        "\n",
        "10. ¬øQu√© significa stream=True al llamar al endpoint de Ollama?\n",
        "\n",
        "11. ¬øQu√© controla la casilla ‚Äúüîä Leer respuestas en voz alta‚Äù?\n",
        "\n",
        "12. ¬øQu√© ocurre si el TextField est√° vac√≠o cuando presionas Enviar?\n",
        "\n",
        "13. ¬øQu√© hace la l√≠nea prompt.on_submit = enviar_click?\n",
        "\n",
        "14. ¬øCon qu√© instrucci√≥n se lanza la app de Flet?\n",
        "\n",
        "15. Si qwen2.5:3b no aparece en ollama list, ¬øqu√© comando debes ejecutar para solucionarlo?"
      ],
      "metadata": {
        "id": "hsAH8kdzt0H2"
      }
    }
  ]
}